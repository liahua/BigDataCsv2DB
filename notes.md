### 分库分表

#### 分表的目的

单表数据数据量达到百万级别后，sql执行效率降低

#### 分库的目的

单库的并发一般为2k，单机磁盘消耗无法承受


#### 分库分表方案


[//]: # (todo 了解一下)
TDSQL，TIDB 

#### 老库如何分库分表设计

双写迁移

##### 实现方案

* 监听canal，增量日志同步更新分库
* 数据校验


#### 分库分表扩容方案

* 成倍扩容
* id取模
* 基于双主同步

##### 例子

* 扩容前

2台机器


| id  | 路由  | 实例   |
|-----|-----|------|
| 0   | 0%2 | db00 |
| 1   | 1%2 | db01 |
| 2   | 2%2 | db00 |
| 3   | 3%2 | db01 |


* 扩容后

4台机器

1. 扩容


| id  | 路由                       | 实例     |
|-----|--------------------------|--------|
| 0   | 0%2 00--> 0%4 --> db0000 | db00   |
| 1   | 1%2 01--> 1%4 --> db0101 | db01   |
| 2   | 2%2 00--> 2%4 --> db0002 | db0001 |
| 3   | 3%2 01--> 3%4 --> db0103 | db0101 |


2. 清数

清理db00 db01中的数据

#### 分库分表后id如何取


* 如果只是单纯数据量多导致的分库分表 可以采用单表获取自增ID接口返回的方式做

* 主键用uuid有什么坏处
  * 数据库不能顺序写入


##### 雪花id

* 应用启动时，db注册workid，看门狗刷新存活时间，定时清理失活pod记录刷新本地workid
* 时钟回拨问题
  * 比较当前时间和lastSecondStamp,设置最大重试时间，将lastSecondStamp设置为当前时间递归重跑



### 缓存

#### 双写不一致

* 读数据
  * 传统Cache注解方式
* 更新数据
  * 更新db,删除缓存
    * lazy加载（容易导致雪崩，看场景）

* 删缓存失败如何处理
  * 先删缓存后更新db
    * 同时有另一个请求进来查询发现没有数据，从数据库读取了旧的数据，此时db才更新完成，导致缓存为旧
  * 延时双删
    * 先更新db,再删缓存，延时再删一次

##### 先删后更新的解决办法

1. 人为将 删缓存更新db 与 查数据查不到缓存加载DB数据作串行同步 （不可取）


### 消息队列

#### kafka

##### 生产者发送数据过慢导致QPS下滑

1. 检查消息体长度是否过长（超过2k）
2. 如果消息体过长建议开启compress.type 压缩算法。



